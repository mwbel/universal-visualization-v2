"""
Performance Manager - Backend Performance Integration
æ€§èƒ½ç®¡ç†å™¨ - åç«¯æ€§èƒ½ä¼˜åŒ–é›†æˆ

æ•´åˆæ‰€æœ‰åç«¯æ€§èƒ½ä¼˜åŒ–ç»„ä»¶ï¼š
- APIä¼˜åŒ–å™¨
- æ•°æ®åº“ä¼˜åŒ–å™¨
- å¹¶å‘å¤„ç†å™¨
- ç›‘æ§å’Œç»Ÿè®¡
"""

import asyncio
import logging
import time
import json
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta

from api_optimizer import APIOptimizer, PerformanceStats
from database_optimizer import DatabaseOptimizer, ConnectionPoolMonitor
from concurrent_optimizer import ConcurrentProcessor, BatchProcessor

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    timestamp: datetime
    api_stats: Dict
    db_stats: Dict
    concurrent_stats: Dict
    system_stats: Dict
    memory_usage: float
    cpu_usage: float

class PerformanceManager:
    """æ€§èƒ½ç®¡ç†å™¨ä¸»ç±»"""

    def __init__(self, config: Dict = None):
        self.config = config or self._get_default_config()

        # åˆå§‹åŒ–å„ç»„ä»¶
        self.api_optimizer = APIOptimizer(
            redis_url=self.config.get('redis_url', 'redis://localhost:6379')
        )

        self.db_optimizer = DatabaseOptimizer(
            config=self.config.get('database', {})
        )

        self.concurrent_processor = ConcurrentProcessor(
            config=self.config.get('concurrent', {})
        )

        self.batch_processor = BatchProcessor(self.concurrent_processor)

        # ç›‘æ§å™¨
        self.pool_monitor = None
        self.performance_stats = PerformanceStats()

        # æ€§èƒ½å†å²æ•°æ®
        self.metrics_history = []
        self.alerts = []

        # è¿è¡ŒçŠ¶æ€
        self.running = False
        self.start_time = None

    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'redis_url': 'redis://localhost:6379',
            'database': {
                'url': 'sqlite+aiosqlite:///./visualization.db',
                'pool_size': 20,
                'max_overflow': 30
            },
            'concurrent': {
                'max_workers': 10,
                'max_concurrent_tasks': 50,
                'task_timeout': 300.0
            },
            'monitoring': {
                'enabled': True,
                'interval': 30,  # 30ç§’
                'metrics_retention_hours': 24,
                'alert_thresholds': {
                    'response_time': 2.0,  # 2ç§’
                    'error_rate': 0.05,    # 5%
                    'memory_usage': 0.85,  # 85%
                    'cpu_usage': 0.80      # 80%
                }
            }
        }

    async def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        try:
            logger.info("ğŸš€ æ€§èƒ½ç®¡ç†å™¨åˆå§‹åŒ–å¼€å§‹")

            # åˆå§‹åŒ–å„ç»„ä»¶
            await self.api_optimizer.initialize()
            await self.db_optimizer.initialize()
            await self.concurrent_processor.start()

            # åˆå§‹åŒ–ç›‘æ§å™¨
            if self.config.get('monitoring', {}).get('enabled', True):
                self.pool_monitor = ConnectionPoolMonitor(self.db_optimizer.engine)

            self.running = True
            self.start_time = datetime.now()

            logger.info("âœ… æ€§èƒ½ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ æ€§èƒ½ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    async def shutdown(self):
        """å…³é—­æ‰€æœ‰ç»„ä»¶"""
        logger.info("ğŸ›‘ æ€§èƒ½ç®¡ç†å™¨å¼€å§‹å…³é—­")

        try:
            self.running = False

            # å…³é—­å„ç»„ä»¶
            await self.concurrent_processor.stop()
            await self.db_optimizer.close()

            logger.info("âœ… æ€§èƒ½ç®¡ç†å™¨å·²å…³é—­")

        except Exception as e:
            logger.error(f"âŒ æ€§èƒ½ç®¡ç†å™¨å…³é—­å¤±è´¥: {e}")

    async def process_api_request(self, request_func, *args, **kwargs):
        """å¤„ç†APIè¯·æ±‚ï¼ˆæ•´åˆæ‰€æœ‰ä¼˜åŒ–ï¼‰"""
        # åº”ç”¨APIä¼˜åŒ–è£…é¥°å™¨
        cached_func = self.api_optimizer.cache_response(ttl=300)(request_func)
        rate_limited_func = self.api_optimizer.rate_limit()(cached_func)
        deduplicated_func = self.api_optimizer.deduplicate_request()(rate_limited_func)
        optimized_func = self.api_optimizer.compress_response()(deduplicated_func)

        # æ‰§è¡Œè¯·æ±‚
        return await optimized_func(*args, **kwargs)

    async def submit_background_task(self, func, *args, **kwargs) -> str:
        """æäº¤åå°ä»»åŠ¡"""
        return await self.concurrent_processor.submit_task(func, *args, **kwargs)

    async def submit_batch_task(self, func, items: List[Any], **kwargs) -> List[str]:
        """æäº¤æ‰¹é‡ä»»åŠ¡"""
        return await self.batch_processor.process_batch(func, items, **kwargs)

    async def get_cached_data(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜æ•°æ®"""
        return await self.api_optimizer.cache.get(key)

    async def set_cached_data(self, key: str, data: Any, ttl: int = 300):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        await self.api_optimizer.cache.set(key, data, ttl)

    async def execute_db_query(self, query: str, params: Dict = None, cache_ttl: int = 300):
        """æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        @self.db_optimizer.cache_query_result(ttl=cache_ttl)
        async def _execute_query():
            return await self.db_optimizer.execute_optimized_query(query, params)

        return await _execute_query()

    async def start_monitoring(self):
        """å¯åŠ¨æ€§èƒ½ç›‘æ§"""
        if not self.config.get('monitoring', {}).get('enabled', True):
            return

        monitoring_interval = self.config.get('monitoring', {}).get('interval', 30)

        while self.running:
            try:
                # æ”¶é›†æ€§èƒ½æŒ‡æ ‡
                metrics = await self._collect_performance_metrics()

                # å­˜å‚¨å†å²æ•°æ®
                self._store_metrics(metrics)

                # æ£€æŸ¥å‘Šè­¦
                await self._check_alerts(metrics)

                # æ¸…ç†æ—§æ•°æ®
                await self._cleanup_old_metrics()

                await asyncio.sleep(monitoring_interval)

            except Exception as e:
                logger.error(f"âŒ æ€§èƒ½ç›‘æ§å¼‚å¸¸: {e}")
                await asyncio.sleep(5)

    async def _collect_performance_metrics(self) -> PerformanceMetrics:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        timestamp = datetime.now()

        # APIç»Ÿè®¡
        api_stats = self.performance_stats.get_stats()

        # æ•°æ®åº“ç»Ÿè®¡
        db_stats = await self.db_optimizer.get_performance_report()

        # å¹¶å‘å¤„ç†ç»Ÿè®¡
        concurrent_stats = await self.concurrent_processor.get_performance_stats()

        # è¿æ¥æ± ç»Ÿè®¡
        pool_stats = {}
        if self.pool_monitor:
            pool_stats = await self.pool_monitor.monitor_pool_health()

        # ç³»ç»Ÿç»Ÿè®¡
        system_stats = await self._get_system_stats()

        return PerformanceMetrics(
            timestamp=timestamp,
            api_stats=api_stats,
            db_stats=db_stats,
            concurrent_stats=concurrent_stats,
            system_stats={**system_stats, 'pool_stats': pool_stats},
            memory_usage=system_stats.get('memory_usage', 0),
            cpu_usage=system_stats.get('cpu_usage', 0)
        )

    async def _get_system_stats(self) -> Dict:
        """è·å–ç³»ç»Ÿç»Ÿè®¡"""
        try:
            import psutil

            return {
                'memory_usage': psutil.virtual_memory().percent / 100,
                'cpu_usage': psutil.cpu_percent() / 100,
                'disk_usage': psutil.disk_usage('/').percent / 100,
                'network_io': {
                    'bytes_sent': psutil.net_io_counters().bytes_sent,
                    'bytes_recv': psutil.net_io_counters().bytes_recv
                }
            }
        except ImportError:
            logger.warning("âš ï¸ psutilæœªå®‰è£…ï¼Œæ— æ³•è·å–ç³»ç»Ÿç»Ÿè®¡")
            return {}

    def _store_metrics(self, metrics: PerformanceMetrics):
        """å­˜å‚¨æ€§èƒ½æŒ‡æ ‡"""
        self.metrics_history.append(metrics)

        # é™åˆ¶å†å²æ•°æ®æ•°é‡
        max_history = self.config.get('monitoring', {}).get('metrics_retention_hours', 24) * 120  # æ¯30ç§’ä¸€ä¸ªç‚¹
        if len(self.metrics_history) > max_history:
            self.metrics_history = self.metrics_history[-max_history:]

    async def _check_alerts(self, metrics: PerformanceMetrics):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        thresholds = self.config.get('monitoring', {}).get('alert_thresholds', {})

        # æ£€æŸ¥å“åº”æ—¶é—´
        avg_response_time = metrics.api_stats.get('average_response_times', {})
        for endpoint, response_time in avg_response_time.items():
            if response_time > thresholds.get('response_time', 2.0):
                await self._create_alert(
                    'high_response_time',
                    f"ç«¯ç‚¹ {endpoint} å“åº”æ—¶é—´è¿‡é«˜: {response_time:.2f}s",
                    metrics
                )

        # æ£€æŸ¥é”™è¯¯ç‡
        total_requests = metrics.api_stats.get('total_requests', 0)
        rate_limited_requests = metrics.api_stats.get('rate_limited_requests', 0)
        error_rate = rate_limited_requests / total_requests if total_requests > 0 else 0

        if error_rate > thresholds.get('error_rate', 0.05):
            await self._create_alert(
                'high_error_rate',
                f"é”™è¯¯ç‡è¿‡é«˜: {error_rate:.2%}",
                metrics
            )

        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        if metrics.memory_usage > thresholds.get('memory_usage', 0.85):
            await self._create_alert(
                'high_memory_usage',
                f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics.memory_usage:.1%}",
                metrics
            )

        # æ£€æŸ¥CPUä½¿ç”¨
        if metrics.cpu_usage > thresholds.get('cpu_usage', 0.80):
            await self._create_alert(
                'high_cpu_usage',
                f"CPUä½¿ç”¨ç‡è¿‡é«˜: {metrics.cpu_usage:.1%}",
                metrics
            )

    async def _create_alert(self, alert_type: str, message: str, metrics: PerformanceMetrics):
        """åˆ›å»ºå‘Šè­¦"""
        alert = {
            'id': len(self.alerts),
            'type': alert_type,
            'message': message,
            'timestamp': metrics.timestamp,
            'metrics': asdict(metrics)
        }

        self.alerts.append(alert)
        logger.warning(f"ğŸš¨ æ€§èƒ½å‘Šè­¦: {message}")

        # é™åˆ¶å‘Šè­¦æ•°é‡
        if len(self.alerts) > 1000:
            self.alerts = self.alerts[-1000]

    async def _cleanup_old_metrics(self):
        """æ¸…ç†æ—§çš„æ€§èƒ½æ•°æ®"""
        retention_hours = self.config.get('monitoring', {}).get('metrics_retention_hours', 24)
        cutoff_time = datetime.now() - timedelta(hours=retention_hours)

        self.metrics_history = [
            metrics for metrics in self.metrics_history
            if metrics.timestamp > cutoff_time
        ]

    async def get_performance_dashboard(self) -> Dict:
        """è·å–æ€§èƒ½ä»ªè¡¨æ¿æ•°æ®"""
        if not self.metrics_history:
            return {'error': 'æš‚æ— æ€§èƒ½æ•°æ®'}

        latest_metrics = self.metrics_history[-1]

        # è®¡ç®—è¶‹åŠ¿
        trends = self._calculate_trends()

        return {
            'current_status': asdict(latest_metrics),
            'trends': trends,
            'alerts': self.alerts[-10:],  # æœ€è¿‘10ä¸ªå‘Šè­¦
            'summary': {
                'uptime_hours': (datetime.now() - self.start_time).total_seconds() / 3600 if self.start_time else 0,
                'total_requests': latest_metrics.api_stats.get('total_requests', 0),
                'cache_hit_rate': latest_metrics.api_stats.get('cache_hit_rate', '0%'),
                'avg_response_time': latest_metrics.api_stats.get('average_response_times', {}),
                'concurrent_tasks_processed': latest_metrics.concurrent_stats.get('tasks_processed', 0),
                'success_rate': latest_metrics.concurrent_stats.get('success_rate', 0),
                'total_alerts': len(self.alerts)
            },
            'recommendations': await self._generate_recommendations(latest_metrics)
        }

    def _calculate_trends(self) -> Dict:
        """è®¡ç®—æ€§èƒ½è¶‹åŠ¿"""
        if len(self.metrics_history) < 2:
            return {}

        recent_metrics = self.metrics_history[-10:]  # æœ€è¿‘10ä¸ªæ•°æ®ç‚¹
        older_metrics = self.metrics_history[-20:-10] if len(self.metrics_history) >= 20 else []

        trends = {}

        # å“åº”æ—¶é—´è¶‹åŠ¿
        recent_avg = sum(m.api_stats.get('total_requests', 0) for m in recent_metrics) / len(recent_metrics)
        if older_metrics:
            older_avg = sum(m.api_stats.get('total_requests', 0) for m in older_metrics) / len(older_metrics)
            trends['requests_trend'] = 'up' if recent_avg > older_avg else 'down'

        # å†…å­˜ä½¿ç”¨è¶‹åŠ¿
        recent_memory = sum(m.memory_usage for m in recent_metrics) / len(recent_metrics)
        if older_metrics:
            older_memory = sum(m.memory_usage for m in older_metrics) / len(older_metrics)
            trends['memory_trend'] = 'up' if recent_memory > older_memory else 'down'

        return trends

    async def _generate_recommendations(self, metrics: PerformanceMetrics) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # åŸºäºå½“å‰æŒ‡æ ‡ç”Ÿæˆå»ºè®®
        if metrics.memory_usage > 0.8:
            recommendations.append("å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–å†…å­˜ä½¿ç”¨æˆ–å¢åŠ å†…å­˜é…ç½®")

        if metrics.cpu_usage > 0.7:
            recommendations.append("CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–ç®—æ³•æˆ–å¢åŠ å¤„ç†èƒ½åŠ›")

        cache_hit_rate = float(metrics.api_stats.get('cache_hit_rate', '0%').rstrip('%'))
        if cache_hit_rate < 50:
            recommendations.append("ç¼“å­˜å‘½ä¸­ç‡è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–ç¼“å­˜ç­–ç•¥")

        if metrics.concurrent_stats.get('tasks_failed', 0) > 0:
            recommendations.append("å­˜åœ¨å¤±è´¥ä»»åŠ¡ï¼Œå»ºè®®æ£€æŸ¥ä»»åŠ¡é€»è¾‘å’Œé”™è¯¯å¤„ç†")

        # åŸºäºå†å²è¶‹åŠ¿ç”Ÿæˆå»ºè®®
        if len(self.metrics_history) >= 10:
            recent_tasks = sum(m.concurrent_stats.get('tasks_processed', 0) for m in self.metrics_history[-10:])
            if recent_tasks == 0:
                recommendations.append("æœ€è¿‘å¤„ç†ä»»åŠ¡æ•°é‡è¾ƒå°‘ï¼Œå¯èƒ½å­˜åœ¨æ€§èƒ½ç“¶é¢ˆ")

        return recommendations

    async def generate_performance_report(self, hours: int = 24) -> Dict:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        relevant_metrics = [
            m for m in self.metrics_history
            if m.timestamp > cutoff_time
        ]

        if not relevant_metrics:
            return {'error': f'è¿‡å»{hours}å°æ—¶å†…æ— æ€§èƒ½æ•°æ®'}

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        total_requests = sum(m.api_stats.get('total_requests', 0) for m in relevant_metrics)
        total_tasks = sum(m.concurrent_stats.get('tasks_processed', 0) for m in relevant_metrics)
        total_failures = sum(m.concurrent_stats.get('tasks_failed', 0) for m in relevant_metrics)

        avg_memory = sum(m.memory_usage for m in relevant_metrics) / len(relevant_metrics)
        avg_cpu = sum(m.cpu_usage for m in relevant_metrics) / len(relevant_metrics)

        # æ‰¾å‡ºå³°å€¼æ—¶é—´
        peak_request_time = max(relevant_metrics, key=lambda m: m.api_stats.get('total_requests', 0))
        peak_memory_time = max(relevant_metrics, key=lambda m: m.memory_usage)

        return {
            'report_period': f'{hours} hours',
            'generated_at': datetime.now().isoformat(),
            'summary': {
                'total_api_requests': total_requests,
                'total_background_tasks': total_tasks,
                'task_success_rate': ((total_tasks - total_failures) / total_tasks * 100) if total_tasks > 0 else 0,
                'average_memory_usage': f'{avg_memory:.1%}',
                'average_cpu_usage': f'{avg_cpu:.1%}',
                'peak_requests_time': peak_request_time.timestamp.isoformat(),
                'peak_requests_count': peak_request_time.api_stats.get('total_requests', 0),
                'peak_memory_time': peak_memory_time.timestamp.isoformat(),
                'peak_memory_usage': f'{peak_memory_time.memory_usage:.1%}'
            },
            'alerts_summary': {
                'total_alerts': len([a for a in self.alerts if a.timestamp > cutoff_time]),
                'alert_types': list(set(a['type'] for a in self.alerts if a.timestamp > cutoff_time))
            },
            'recommendations': await self._generate_recommendations(relevant_metrics[-1]),
            'detailed_metrics': [asdict(m) for m in relevant_metrics[::6]]  # æ¯6ä¸ªæ•°æ®ç‚¹å–ä¸€ä¸ª
        }

# FastAPIé›†æˆç¤ºä¾‹
"""
from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import JSONResponse

app = FastAPI()
performance_manager = PerformanceManager()

@app.on_event("startup")
async def startup():
    await performance_manager.initialize()
    # å¯åŠ¨ç›‘æ§
    asyncio.create_task(performance_manager.start_monitoring())

@app.on_event("shutdown")
async def shutdown():
    await performance_manager.shutdown()

@app.post("/api/visualize")
async def generate_visualization(request: Request, data: dict):
    try:
        # ä½¿ç”¨æ€§èƒ½ç®¡ç†å™¨å¤„ç†è¯·æ±‚
        result = await performance_manager.process_api_request(
            _generate_visualization_impl,
            request=request,
            data=data
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@performance_manager.api_optimizer.cache_response(ttl=300)
@performance_manager.api_optimizer.rate_limit()
async def _generate_visualization_impl(request: Request, data: dict):
    # å®é™…çš„å¯è§†åŒ–ç”Ÿæˆé€»è¾‘
    await asyncio.sleep(1)  # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
    return {"status": "success", "data": data}

@app.get("/api/performance/dashboard")
async def get_performance_dashboard():
    return await performance_manager.get_performance_dashboard()

@app.get("/api/performance/report")
async def get_performance_report(hours: int = 24):
    return await performance_manager.generate_performance_report(hours)
"""

# ä½¿ç”¨ç¤ºä¾‹
"""
async def main():
    # åˆ›å»ºæ€§èƒ½ç®¡ç†å™¨
    manager = PerformanceManager()

    # åˆå§‹åŒ–
    await manager.initialize()

    # å¯åŠ¨ç›‘æ§ï¼ˆåœ¨åå°è¿è¡Œï¼‰
    monitoring_task = asyncio.create_task(manager.start_monitoring())

    try:
        # æäº¤ä¸€äº›ä»»åŠ¡
        task_id = await manager.submit_background_task(
            lambda: asyncio.sleep(2) or "Task completed"
        )

        # è·å–æ€§èƒ½æ•°æ®
        dashboard = await manager.get_performance_dashboard()
        print("Performance Dashboard:", json.dumps(dashboard, indent=2, default=str))

        # ç­‰å¾…ä¸€æ®µæ—¶é—´æ”¶é›†æ•°æ®
        await asyncio.sleep(60)

        # ç”ŸæˆæŠ¥å‘Š
        report = await manager.generate_performance_report(1)  # æœ€è¿‘1å°æ—¶
        print("Performance Report:", json.dumps(report, indent=2, default=str))

    finally:
        # å…³é—­
        await manager.shutdown()

if __name__ == "__main__":
    asyncio.run(main())
"""